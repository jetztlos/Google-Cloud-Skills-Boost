{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "export LANGUAGE=French\n",
        "export LOCALE=fr\n",
        "export BIGQUERY_ROLE=roles/bigquery.dataOwner\n",
        "export CLOUD_STORAGE_ROLE=roles/storage.admin\n",
        "export SERVICE_ACCOUNT=new-sa"
      ],
      "metadata": {
        "id": "16YwkZdCXaYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 1. Configure a service account to access the Machine Learning APIs, BigQuery, and Cloud Storage"
      ],
      "metadata": {
        "id": "jaCuJi--W2Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new service account that provides credentials for the script\n",
        "gcloud iam service-accounts create $SERVICE_ACCOUNT"
      ],
      "metadata": {
        "id": "iwlos43EXKHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once you have created the account, bind the roles/bigquery.dataOwner and roles/storage.admin roles to the Service Account\n",
        "# to provide the IAM permissions required to process files from Cloud Storage and insert the result data into a BigQuery table\n",
        "\n",
        "gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID --member=serviceAccount:$SERVICE_ACCOUNT@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role=$BIGQUERY_ROLE\n",
        "\n",
        "gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID --member=serviceAccount:$SERVICE_ACCOUNT@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role=$CLOUD_STORAGE_ROLE\n",
        "\n",
        "gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID --member=serviceAccount:$SERVICE_ACCOUNT@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role=roles/serviceusage.serviceUsageConsumer\n"
      ],
      "metadata": {
        "id": "_Qt3fDdvYmpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2. Create and download a credential file for your service account"
      ],
      "metadata": {
        "id": "npTJM3_WW1_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# When you have configured the service account permissions, download the JSON format IAM credentials file for the service account\n",
        "gcloud iam service-accounts keys create $SERVICE_ACCOUNT-key.json --iam-account $SERVICE_ACCOUNT@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com"
      ],
      "metadata": {
        "id": "snn9fcAGXKir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't forget to configure the environment variable that supplies the name of the credential file for the Python script\n",
        "export GOOGLE_APPLICATION_CREDENTIALS=${PWD}/$SERVICE_ACCOUNT-key.json"
      ],
      "metadata": {
        "id": "kQE67caDZekv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 3. Modify the Python script to extract text from image files"
      ],
      "metadata": {
        "id": "5fugUV2RW18y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the file analyze-images-v2.py from the Cloud Storage bucket\n",
        "gsutil cp gs://qwiklabs-gcp-04-4c92716181fb/analyze-images-v2.py ."
      ],
      "metadata": {
        "id": "0Q77es1-XK7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify this Python script to extract text from the image files stored in your project bucket and then\n",
        "# save the text data for each file into a text file that is written back to the same bucket\n",
        "\n",
        "# sed -i \"s/'en'/'${LOCAL}'/g\" analyze-images-v2.py\n",
        "# vi analyze-images-v2.py\n",
        "\n",
        "# or [Open Editor]"
      ],
      "metadata": {
        "id": "PKrAPAz-Z6jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: image_classification_dataset\n",
        "# Table name: image_text_detail\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Import Google Cloud Library modules\n",
        "from google.cloud import storage, bigquery, language, vision, translate_v2\n",
        "\n",
        "if ('GOOGLE_APPLICATION_CREDENTIALS' in os.environ):\n",
        "    if (not os.path.exists(os.environ['GOOGLE_APPLICATION_CREDENTIALS'])):\n",
        "        print (\"The GOOGLE_APPLICATION_CREDENTIALS file does not exist.\\n\")\n",
        "        exit()\n",
        "else:\n",
        "    print (\"The GOOGLE_APPLICATION_CREDENTIALS environment variable is not defined.\\n\")\n",
        "    exit()\n",
        "\n",
        "if len(sys.argv)<3:\n",
        "    print('You must provide parameters for the Google Cloud project ID and Storage bucket')\n",
        "    print ('python3 '+sys.argv[0]+ '[PROJECT_NAME] [BUCKET_NAME]')\n",
        "    exit()\n",
        "\n",
        "project_name = sys.argv[1]\n",
        "bucket_name = sys.argv[2]\n",
        "\n",
        "# Set up our GCS, BigQuery, and Natural Language clients\n",
        "storage_client = storage.Client()\n",
        "bq_client = bigquery.Client(project=project_name)\n",
        "nl_client = language.LanguageServiceClient()\n",
        "\n",
        "# Set up client objects for the vision and translate_v2 API Libraries\n",
        "vision_client = vision.ImageAnnotatorClient()\n",
        "translate_client = translate_v2.Client()\n",
        "\n",
        "# Setup the BigQuery dataset and table objects\n",
        "dataset_ref = bq_client.dataset('image_classification_dataset')\n",
        "dataset = bigquery.Dataset(dataset_ref)\n",
        "table_ref = dataset.table('image_text_detail')\n",
        "table = bq_client.get_table(table_ref)\n",
        "\n",
        "# Create an array to store results data to be inserted into the BigQuery table\n",
        "rows_for_bq = []\n",
        "\n",
        "# Get a list of the files in the Cloud Storage Bucket\n",
        "files = storage_client.bucket(bucket_name).list_blobs()\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "print('Processing image files from GCS. This will take a few minutes..')\n",
        "\n",
        "# Process files from Cloud Storage and save the result to send to BigQuery\n",
        "for file in files:\n",
        "    if file.name.endswith('jpg') or  file.name.endswith('png'):\n",
        "        file_content = file.download_as_string()\n",
        "\n",
        "        # TBD: Create a Vision API image object called image_object\n",
        "        # Ref: https://googleapis.dev/python/vision/latest/gapic/v1/types.html#google.cloud.vision_v1.types.Image\n",
        "        from google.cloud import vision_v1\n",
        "        import io\n",
        "        client = vision.ImageAnnotatorClient()\n",
        "\n",
        "        # TBD: Detect text in the image and save the response data into an object called response\n",
        "        # Ref: https://googleapis.dev/python/vision/latest/gapic/v1/api.html#google.cloud.vision_v1.ImageAnnotatorClient.document_text_detection\n",
        "        image = vision_v1.types.Image(content=file_content)\n",
        "        response = client.text_detection(image=image)\n",
        "\n",
        "        # Save the text content found by the vision API into a variable called text_data\n",
        "        text_data = response.text_annotations[0].description\n",
        "\n",
        "        # Save the text detection response data in <filename>.txt to cloud storage\n",
        "        file_name = file.name.split('.')[0] + '.txt'\n",
        "        blob = bucket.blob(file_name)\n",
        "        # Upload the contents of the text_data string variable to the Cloud Storage file\n",
        "        blob.upload_from_string(text_data, content_type='text/plain')\n",
        "\n",
        "        # Extract the description and locale data from the response file\n",
        "        # into variables called desc and locale\n",
        "        # using response object properties e.g. response.text_annotations[0].description\n",
        "        desc = response.text_annotations[0].description\n",
        "        locale = response.text_annotations[0].locale\n",
        "\n",
        "        # TBD: Save the description as the translated text into target_language eg. '', 'fe', and 'ja' according to the lab manual .\n",
        "        if locale == 'fr':\n",
        "            translated_text = desc\n",
        "        else:\n",
        "            # TBD: According to the target language pass the description data to the translation API\n",
        "            # ref: https://googleapis.dev/python/translation/latest/client.html#google.cloud.translate_v2.client.Client.translate\n",
        "            # Set the target_language locale to according to the lab activity)\n",
        "            from google.cloud import translate_v2 as translate\n",
        "            client = translate.Client()\n",
        "            translation = translate_client.translate(text_data, target_language='fr')\n",
        "            translated_text = translation['translatedText']\n",
        "        print(translated_text)\n",
        "\n",
        "        # if there is response data save the original text read from the image,\n",
        "        # the locale, translated text, and filename\n",
        "        if len(response.text_annotations) > 0:\n",
        "            rows_for_bq.append((desc, locale, translated_text, file.name))\n",
        "\n",
        "print('Writing Vision API image data to BigQuery...')\n",
        "# Write original text, locale and translated text to BQ\n",
        "# TBD: When the script is working uncomment the next line to upload results to BigQuery\n",
        "errors = bq_client.insert_rows(table, rows_for_bq)\n",
        "assert errors == []"
      ],
      "metadata": {
        "id": "uMmq90rsinK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the partially completed script to check your progress to make sure you are on the right track\n",
        "\n",
        "python3 analyze-images-v2.py $DEVSHELL_PROJECT_ID qwiklabs-gcp-04-4c92716181fb"
      ],
      "metadata": {
        "id": "sxnTt5jNZ6Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 4. Modify the Python script to translate the text using the Translation API"
      ],
      "metadata": {
        "id": "CGOOLD9JW15H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the second part of the Python script to identify any non-French text data found by the Vision API and\n",
        "# use the Translation API to translate the original text into French\n",
        "\n",
        "python3 analyze-images-v2.py $DEVSHELL_PROJECT_ID qwiklabs-gcp-04-4c92716181fb"
      ],
      "metadata": {
        "id": "F5T9f8CBXLUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 5. Identify the most common language used in the signs in the dataset"
      ],
      "metadata": {
        "id": "ztgo2vnxW1uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the comment character from the line at the end of the script that uploads the data to BigQuery\n",
        "\n",
        "python3 analyze-images-v2.py $DEVSHELL_PROJECT_ID qwiklabs-gcp-04-4c92716181fb"
      ],
      "metadata": {
        "id": "c5jOhPA_av_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm that all necessary data has been loaded into BigQuery by running a query that counts the number of times it sees each separate language\n",
        "\n",
        "# bq query --use_legacy_sql=false \"SELECT locale,COUNT(locale) as lcount FROM image_classification_dataset.image_text_detail GROUP BY locale ORDER BY lcount DESC\"\n",
        "\n",
        "# or BQ -> +SQL\n",
        "SELECT locale,COUNT(locale) as lcount FROM image_classification_dataset.image_text_detail GROUP BY locale ORDER BY lcount DESC"
      ],
      "metadata": {
        "id": "h4T8kGI1av8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATs7qwCokY5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clskjBxSav6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tlDKYfUWsXV"
      },
      "outputs": [],
      "source": []
    }
  ]
}