{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Task 1. Create an API key"
      ],
      "metadata": {
        "id": "7OFm_PbKFe2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# APIs & services -> Credentials"
      ],
      "metadata": {
        "id": "QawRcdZ5Fi2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2. Make an entity analysis request and call the Natural Language API"
      ],
      "metadata": {
        "id": "jPeLrzoOFeyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Engine -> lab-vm -> SSH\n",
        "export API_KEY=AIzaSyBkLEnvg6By3RYE671rpCEFPMeVAA5k9mg"
      ],
      "metadata": {
        "id": "Mtbq0M-6GIqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "touch nl_request.json\n",
        "nano nl_request.json"
      ],
      "metadata": {
        "id": "8zDk0o82FnD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"document\":{\n",
        "    \"type\":\"PLAIN_TEXT\",\n",
        "    \"content\":\"With approximately 8.2 million people residing in Boston, the capital city of Massachusetts is one of the largest in the United States.\"\n",
        "  },\n",
        "  \"encodingType\":\"UTF8\"\n",
        "}\n",
        "# Ctrl + X -> Y -> Enter"
      ],
      "metadata": {
        "id": "upKShsPKGXKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curl \"https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}\" \\\n",
        "  -s -X POST -H \"Content-Type: application/json\" --data-binary @nl_request.json > nl_response.json"
      ],
      "metadata": {
        "id": "jUAuko0dGXG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 3. Create a speech analysis request and call the Speech API"
      ],
      "metadata": {
        "id": "zfQooftVFev8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "touch speech_request.json\n",
        "nano speech_request.json"
      ],
      "metadata": {
        "id": "2Vm8Bkv5FsMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"config\": {\n",
        "      \"encoding\":\"FLAC\",\n",
        "      \"languageCode\": \"en-US\"\n",
        "  },\n",
        "  \"audio\": {\n",
        "      \"uri\":\"gs://cloud-samples-tests/speech/brooklyn.flac\"\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "KlnnBeozGs50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curl -s -X POST -H \"Content-Type: application/json\" --data-binary @speech_request.json \\\n",
        "\"https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}\""
      ],
      "metadata": {
        "id": "LXfww9C6Gszn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curl -s -X POST -H \"Content-Type: application/json\" --data-binary @speech_request.json \\\n",
        "\"https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}\" > speech_response.json"
      ],
      "metadata": {
        "id": "7ttzo8FJGseh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 4. Analyze sentiment with the Natural Language API"
      ],
      "metadata": {
        "id": "b3Ztpd0LFet9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nano sentiment_analysis.py"
      ],
      "metadata": {
        "id": "VKfXDjGsFwRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "from google.cloud import language_v1\n",
        "\n",
        "def print_result(annotations):\n",
        "    score = annotations.document_sentiment.score\n",
        "    magnitude = annotations.document_sentiment.magnitude\n",
        "\n",
        "    for index, sentence in enumerate(annotations.sentences):\n",
        "        sentence_sentiment = sentence.sentiment.score\n",
        "        print(\n",
        "            f\"Sentence {index} has a sentiment score of {sentence_sentiment}\"\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Overall Sentiment: score of {score} with magnitude of {magnitude}\"\n",
        "    )\n",
        "    return 0\n",
        "\n",
        "\n",
        "def analyze(movie_review_filename):\n",
        "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    with open(movie_review_filename) as review_file:\n",
        "        # Instantiates a plain text document.\n",
        "        content = review_file.read()\n",
        "\n",
        "    document = language_v1.Document(\n",
        "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
        "    )\n",
        "    annotations = client.analyze_sentiment(request={\"document\": document})\n",
        "\n",
        "    # Print the results\n",
        "    print_result(annotations)\n",
        "\n",
        "if _name_ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"movie_review_filename\",\n",
        "        help=\"The filename of the movie review you'd like to analyze.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    analyze(args.movie_review_filename)"
      ],
      "metadata": {
        "id": "ooIi-WJdG-gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative\n",
        "cat > sentiment_analysis.py <<EOF\n",
        "\n",
        "import argparse\n",
        "\n",
        "from google.cloud import language_v1\n",
        "\n",
        "def print_result(annotations):\n",
        "    score = annotations.document_sentiment.score\n",
        "    magnitude = annotations.document_sentiment.magnitude\n",
        "\n",
        "    for index, sentence in enumerate(annotations.sentences):\n",
        "        sentence_sentiment = sentence.sentiment.score\n",
        "        print(\n",
        "            f\"Sentence {index} has a sentiment score of {sentence_sentiment}\"\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Overall Sentiment: score of {score} with magnitude of {magnitude}\"\n",
        "    )\n",
        "    return 0\n",
        "\n",
        "\n",
        "def analyze(movie_review_filename):\n",
        "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    with open(movie_review_filename) as review_file:\n",
        "        # Instantiates a plain text document.\n",
        "        content = review_file.read()\n",
        "\n",
        "    document = language_v1.Document(\n",
        "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
        "    )\n",
        "    annotations = client.analyze_sentiment(request={\"document\": document})\n",
        "\n",
        "    # Print the results\n",
        "    print_result(annotations)\n",
        "\n",
        "if _name_ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"movie_review_filename\",\n",
        "        help=\"The filename of the movie review you'd like to analyze.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    analyze(args.movie_review_filename)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "a5QIGXhpHRjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gsutil cp gs://cloud-samples-tests/natural-language/sentiment-samples.tgz ."
      ],
      "metadata": {
        "id": "WXsboTvGHLPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gunzip sentiment-samples.tgz"
      ],
      "metadata": {
        "id": "YAJ1jpHrIXPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar -xvf sentiment-samples.tar"
      ],
      "metadata": {
        "id": "EjOHqyXQIXFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python3 sentiment_analysis.py reviews/bladerunner-pos.tx"
      ],
      "metadata": {
        "id": "TCEal9PEHLFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSX8TG24FYmA"
      },
      "outputs": [],
      "source": []
    }
  ]
}